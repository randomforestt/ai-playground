{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll be implementing a classical dynamic programming algorithms to figure out the best action to take in a toy problem environment called slippery frozen lake 👩 \n",
    "\n",
    "# Slippery Frozen Lake Environment\n",
    "\n",
    "[Modified version of the description from Open AI Gym](https://gym.openai.com/envs/FrozenLake-v0/)\n",
    "\n",
    "> The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into holes with exploding 💥 bombs 💥 and die (I know right!) . Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "\n",
    "> You want to get to the target 🎯. The lake is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water (where there is a BOMB 💥and you will EXPLODE 💥and DIE 💥). You navigate across the lake and go to the target 🎯. **However, the ice is slippery, so you won't always move in the direction you intend.**\n",
    "\n",
    "> The episode ends when you reach the goal or fall in the hole with bomb and die!. You receive a reward of **+1** if you reach the goal 🎯, and **zero** otherwise.\n",
    "\n",
    "# STATES\n",
    "\n",
    "```\n",
    "S - 👩🏼 (S: starting point, safe, REWARD = 0)\n",
    "F - ▫️ (F: frozen surface, safe, REWARD = 0)\n",
    "H - 💥 (H: hole with bomb, fall to your doom, terminal state, REWARD = 0)\n",
    "G - 🎯 (G: goal, dartboard target, safe, terminal state, REWARD = +1) \n",
    "\n",
    "👩▫️▫️▫️ | SFFF \n",
    "▫️💥▫️💥 | FHFH \n",
    "▫️▫️▫️💥 | FFFH\n",
    "💥▫️▫️🎯 | HFFG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frozen_lake import SlipperyFrozenLake, FrozenLakeState, a_few_tests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED! :) \n"
     ]
    }
   ],
   "source": [
    "a_few_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_lake_map = [\n",
    "    ['S', 'F', 'F', 'F'], \n",
    "    ['F', 'H', 'F', 'H'],\n",
    "    ['F', 'F', 'F', 'H'],\n",
    "    ['H', 'F', 'F', 'G']]\n",
    "\n",
    "lake_environment = SlipperyFrozenLake(frozen_lake_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Frozen Lake Environment\n",
    "\n",
    "## chars ( S, F, H, G) - state condition\n",
    "\n",
    "```\n",
    "  0   1   2   3\n",
    "  +---+---+---+---+\n",
    "0 | S | F | F | F |\n",
    "  +---+---+---+---+\n",
    "1 | F | H | F | H |\n",
    "  +---+---+---+---+\n",
    "2 | F | F | F | H |\n",
    "  +---+---+---+---+\n",
    "3 | H | F | F | G |\n",
    "  +---+---+---+---+\n",
    "```\n",
    "\n",
    "## icons ( 👩 ▫️  💥🎯)\n",
    "\n",
    "```\n",
    "\n",
    "  0   1   2   3\n",
    "  +---+---+---+---+\n",
    "0 |👩 |▫️ |▫️ |▫️|\n",
    "  +---+---+---+---+\n",
    "1 |▫️ |💥 |▫️ |💥|\n",
    "  +---+---+---+---+\n",
    "2 |▫️ |▫️ |▫️ |💥|\n",
    "  +---+---+---+---+\n",
    "3 |💥 |▫️ |▫️ |🎯|\n",
    "  +---+---+---+---+\n",
    "\n",
    "```\n",
    "\n",
    "## terminal ( y / n )\n",
    "\n",
    "```\n",
    "  0   1   2   3\n",
    "  +---+---+---+---+\n",
    "0 | n | n | n | n |\n",
    "  +---+---+---+---+\n",
    "1 | n | y | n | y |\n",
    "  +---+---+---+---+\n",
    "2 | n | n | n | y |\n",
    "  +---+---+---+---+\n",
    "3 | y | n | n | y |\n",
    "  +---+---+---+---+\n",
    "```\n",
    "\n",
    "## state number \n",
    "```\n",
    "  0   1   2   3\n",
    "  +---+---+---+---+\n",
    "0 | 0 | 1 | 2 | 3 |\n",
    "  +---+---+---+---+\n",
    "1 | 4 | 5 | 6 | 7 |\n",
    "  +---+---+---+---+\n",
    "2 | 8 | 9 |10 |11 |\n",
    "  +---+---+---+---+\n",
    "3 |12 |13 |14 |15 |\n",
    "  +---+---+---+---+\n",
    "```\n",
    "\n",
    "## rewards\n",
    "\n",
    "```\n",
    "  0   1   2   3\n",
    "  +---+---+---+---+\n",
    "0 | 0 | 0 | 0 | 0 |\n",
    "  +---+---+---+---+\n",
    "1 | 0 | 0 | 0 | 0 |\n",
    "  +---+---+---+---+\n",
    "2 | 0 | 0 | 0 | 0 |\n",
    "  +---+---+---+---+\n",
    "3 | 0 | 0 | 0 |+1 |\n",
    "  +---+---+---+---+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-->A 4x4 Grid World\n",
      "[['S', 'F', 'F', 'F'],\n",
      " ['F', 'H', 'F', 'H'],\n",
      " ['F', 'F', 'F', 'H'],\n",
      " ['H', 'F', 'F', 'G']]\n",
      "\n",
      "-->Number of states: 16\n",
      "-->And potential actions to take: ['up', 'down', 'left', 'right']\n",
      "\n",
      "-->With respective states numbered as follows:\n",
      "\n",
      "   0   1   2   3\n",
      "   4   5   6   7\n",
      "   8   9  10  11\n",
      "  12  13  14  15\n",
      "\n",
      "-->Total number of states: 16\n",
      "\n",
      "--------------------\n",
      "Possible Conditions for each state\n",
      "--------------------\n",
      "\n",
      "state condition (char): S\n",
      "-->Reward: 0.0\n",
      "-->Is terminal?: False\n",
      "-->Icon: 👩\n",
      "\n",
      "\n",
      "state condition (char): H\n",
      "-->Reward: 0.0\n",
      "-->Is terminal?: True\n",
      "-->Icon: 💥\n",
      "\n",
      "\n",
      "state condition (char): F\n",
      "-->Reward: 0.0\n",
      "-->Is terminal?: False\n",
      "-->Icon: ▫️\n",
      "\n",
      "\n",
      "state condition (char): G\n",
      "-->Reward: 1.0\n",
      "-->Is terminal?: True\n",
      "-->Icon: 🎯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"-->A 4x4 Grid World\")\n",
    "pprint(lake_environment.map)\n",
    "\n",
    "print()\n",
    "print(\"-->Number of states:\", lake_environment.number_of_states)\n",
    "print(\"-->And potential actions to take:\", lake_environment.actions)\n",
    "\n",
    "print()\n",
    "print(\"-->With respective states numbered as follows:\")\n",
    "print()\n",
    "for r in lake_environment.n_map:\n",
    "    for c in r: \n",
    "        print('{:4d}'.format(c), end=\"\")\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(\"-->Total number of states:\", lake_environment.number_of_states)\n",
    "print()\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(\"Possible Conditions for each state\")\n",
    "print(\"--------------------\")\n",
    "\n",
    "for c in ['S', 'H', 'F', 'G']:\n",
    "    print()\n",
    "    print('state condition (char):', c)\n",
    "    print(\"-->Reward:\", lake_environment.reward[c])\n",
    "    print(\"-->Is terminal?:\", lake_environment.is_terminal[c])\n",
    "    print(\"-->Icon:\", lake_environment.icons[c])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming\n",
    "\n",
    "Dynamic programming assumes that the agent has full knowledge of the Markov Decision Process (MDP). We have the full knowledge of each one step dynamic of each state. \n",
    "\n",
    "For example you can run the following: \n",
    "\n",
    "```\n",
    "possibilities = lake_environment.get_possibilities(state_number, action)\n",
    "```\n",
    "\n",
    "You get a `list` (aka `array`) of `FrozenLakeState` objects which each contains \n",
    "- probability of transitioning to this particular state `next_s` number given you came from a given state number and took the particular action \n",
    "- The corresponding reward `r` of landing to this next state `next_s`\n",
    "- If this state is a terminal state \n",
    "- Among other useful formation\n",
    "\n",
    "> DEFINITION: the **Transition Probability** of a state `s` (with corresponding current `state_number`) at time `t`, action `a` at timestep `t` and possible state `s'` (with corresponding `possible_state_number`) is the probability that the next state at timestep `t+1` is the possible_state `s'` given that at state `s` you do action `a`. \n",
    "\n",
    "```\n",
    "*\n",
    "\n",
    "transition_probability(s, a, s') = probability[state(t+1) = s'| state(t) = s, action(t) = a]\n",
    "\n",
    "*\n",
    "```\n",
    "\n",
    "> The idea is that the surface is slippery, therefore the agent can slide to a location other than the one it wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "From state:  6  do action:  down !\n",
      "***\n",
      "\n",
      "# 1\n",
      "--> next state:  10\n",
      "--> reward: 0.0\n",
      "--> probability:  0.3333333333333333\n",
      "--> is terminal:  False\n",
      "\n",
      "\n",
      "# 2\n",
      "--> next state:  5\n",
      "--> reward: 0.0\n",
      "--> probability:  0.3333333333333333\n",
      "--> is terminal:  True\n",
      "\n",
      "\n",
      "# 3\n",
      "--> next state:  7\n",
      "--> reward: 0.0\n",
      "--> probability:  0.3333333333333333\n",
      "--> is terminal:  True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lake_environment.get_possibilities(\n",
    "    state_number=6, action='down', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "# 1\n",
      "--\n",
      "\n",
      "*FrozenLakeState (TYPE) \n",
      "--> State Number: 0\n",
      "--> Reward: 0.0\n",
      "--> Not a terminal state. \n",
      "--> (Transition) Probability (given state_number and action): 0.3333333333333333\n",
      "--> Icon: 👩\n",
      "--> Character representation of state condition: 'S'\n",
      "--> Location: (0,0) \n",
      "\n",
      "\n",
      "--\n",
      "# 2\n",
      "--\n",
      "\n",
      "*FrozenLakeState (TYPE) \n",
      "--> State Number: 0\n",
      "--> Reward: 0.0\n",
      "--> Not a terminal state. \n",
      "--> (Transition) Probability (given state_number and action): 0.3333333333333333\n",
      "--> Icon: 👩\n",
      "--> Character representation of state condition: 'S'\n",
      "--> Location: (0,0) \n",
      "\n",
      "\n",
      "--\n",
      "# 3\n",
      "--\n",
      "\n",
      "*FrozenLakeState (TYPE) \n",
      "--> State Number: 1\n",
      "--> Reward: 0.0\n",
      "--> Not a terminal state. \n",
      "--> (Transition) Probability (given state_number and action): 0.3333333333333333\n",
      "--> Icon: ▫️\n",
      "--> Character representation of state condition: 'F'\n",
      "--> Location: (0,1) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "possibilities = lake_environment.get_possibilities(\n",
    "    state_number=0, action='up', debug=False)\n",
    "\n",
    "for i, state_info in enumerate(possibilities):\n",
    "    \n",
    "    print(\"--\")\n",
    "    print(\"#\", i + 1)\n",
    "    print(\"--\")\n",
    "\n",
    "    print(state_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in state number: 14, and you do action: right\n",
      "--\n",
      "# 1\n",
      "--\n",
      "next_state:  15\n",
      "reward:  1.0\n",
      "this is a terminal state? True\n",
      "probability of transitioning to this state\n",
      "coming from state number 14 and going right:  0.3333333333333333\n",
      "--\n",
      "# 2\n",
      "--\n",
      "next_state:  10\n",
      "reward:  0.0\n",
      "this is a terminal state? False\n",
      "probability of transitioning to this state\n",
      "coming from state number 14 and going right:  0.3333333333333333\n",
      "--\n",
      "# 3\n",
      "--\n",
      "next_state:  14\n",
      "reward:  0.0\n",
      "this is a terminal state? False\n",
      "probability of transitioning to this state\n",
      "coming from state number 14 and going right:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "possibilities = lake_environment.get_possibilities(\n",
    "    state_number=14, action='right', debug=False)\n",
    "\n",
    "print(\"You are in state number: 14, and you do action: right\")\n",
    "for i, state_info in enumerate(possibilities):\n",
    "    \n",
    "    print(\"--\")\n",
    "    print(\"#\", i + 1)\n",
    "    print(\"--\")\n",
    "\n",
    "    print(\"next_state: \", state_info.n)\n",
    "    print(\"reward: \", state_info.reward)\n",
    "    print(\"this is a terminal state?\", state_info.is_terminal)\n",
    "    print(\"probability of transitioning to this state\")\n",
    "    print(\"coming from state number 14 and going right: \", state_info.probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "From state:  7  do action:  left !\n",
      "***\n",
      "\n",
      "# 1\n",
      "--> next state:  7\n",
      "--> reward: 0.0\n",
      "--> probability:  1.0\n",
      "--> is terminal:  True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lake_environment.get_possibilities(\n",
    "    state_number=7, action='left', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 1: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 2: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 3: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 4: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 5: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 6: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 7: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 8: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 9: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 10: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 11: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 12: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 13: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 14: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25},\n",
      " 15: {'down': 0.25, 'left': 0.25, 'right': 0.25, 'up': 0.25}}\n"
     ]
    }
   ],
   "source": [
    "def create_equiprobable_policy(env):\n",
    "\n",
    "    # probability of taking an action given the state \n",
    "    p = 1.0 / len(env.actions)\n",
    "    \n",
    "    policy_for_any_state = {}\n",
    "    policy = {}\n",
    "    for action in env.actions:\n",
    "        policy_for_any_state[action] = p\n",
    "    \n",
    "    for state_number in range(env.number_of_states):\n",
    "        policy[state_number] = policy_for_any_state\n",
    "    \n",
    "    return policy\n",
    "\n",
    "policy = create_equiprobable_policy(env = lake_environment)\n",
    "pprint(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.25 0.  ]\n",
      "2\n",
      "[0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.0625  0.      0.      0.0625  0.34375 0.     ]\n",
      "3\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.015625   0.         0.         0.03125    0.09765625 0.\n",
      " 0.         0.109375   0.38769531 0.        ]\n",
      "4\n",
      "[0.         0.         0.00390625 0.00097656 0.         0.\n",
      " 0.02539062 0.         0.0078125  0.05371094 0.11669922 0.\n",
      " 0.         0.13769531 0.41052246 0.        ]\n",
      "5\n",
      "[0.         0.00097656 0.0078125  0.00244141 0.00195312 0.\n",
      " 0.03112793 0.         0.01586914 0.06756592 0.12730408 0.\n",
      " 0.         0.15394592 0.42294312 0.        ]\n",
      "6\n",
      "[0.00073242 0.00238037 0.01094055 0.00395584 0.00463867 0.\n",
      " 0.03456116 0.         0.02201843 0.07581711 0.13333035 0.\n",
      " 0.         0.16317654 0.4298625  0.        ]\n",
      "7\n",
      "[0.00212097 0.00386047 0.01332951 0.0053103  0.00719452 0.\n",
      " 0.03666496 0.         0.02625751 0.0806911  0.13680464 0.\n",
      " 0.         0.16843253 0.43377492 0.        ]\n",
      "8\n",
      "[0.00382423 0.00525355 0.01513958 0.00644004 0.00931907 0.\n",
      " 0.03798606 0.         0.02906692 0.08357602 0.13883425 0.\n",
      " 0.         0.17144587 0.43601376 0.        ]\n",
      "9\n",
      "[0.00555527 0.0064871  0.01651319 0.00734832 0.01098531 0.\n",
      " 0.03883686 0.         0.03090706 0.0852968  0.14003685 0.\n",
      " 0.         0.17318911 0.43730993 0.        ]\n",
      "10\n",
      "[0.00714574 0.00753651 0.01755872 0.00806384 0.01225953 0.\n",
      " 0.03939889 0.         0.03211585 0.08633545 0.14076107 0.\n",
      " 0.         0.17420862 0.43806991 0.        ]\n",
      "11\n",
      "[0.00852188 0.00840428 0.01835643 0.00862103 0.01322431 0.\n",
      " 0.03977938 0.         0.0329189  0.08697215 0.14120536 0.\n",
      " 0.         0.17481267 0.43852198 0.        ]\n",
      "12\n",
      "[0.00966809 0.0091072  0.01896601 0.00905202 0.01395283 0.\n",
      " 0.04004284 0.         0.03346097 0.08736975 0.14148364 0.\n",
      " 0.         0.1751761  0.43879543 0.        ]\n",
      "13\n",
      "[0.01059905 0.00966806 0.01943223 0.00938407 0.01450321 0.\n",
      " 0.04022897 0.         0.03383348 0.08762331 0.14166193 0.\n",
      " 0.         0.17539871 0.43896402 0.        ]\n",
      "14\n",
      "[0.01134234 0.01011066 0.01978898 0.00963928 0.01491976 0.\n",
      " 0.04036273 0.         0.03409414 0.08778869 0.14177886 0.\n",
      " 0.         0.17553785 0.43907018 0.        ]\n",
      "15\n",
      "[0.01192878 0.01045711 0.02006202 0.00983515 0.01523567 0.\n",
      " 0.04046022 0.         0.03427962 0.08789908 0.14185737 0.\n",
      " 0.         0.17562678 0.43913858 0.        ]\n",
      "16\n",
      "[0.01238758 0.01072668 0.02027102 0.00998533 0.01547572 0.\n",
      " 0.0405321  0.         0.03441361 0.08797444 0.14191128 0.\n",
      " 0.         0.17568495 0.4391837  0.        ]\n",
      "17\n",
      "[0.01274439 0.01093552 0.02043099 0.01010041 0.01565843 0.\n",
      " 0.04058557 0.         0.03451162 0.08802696 0.14194906 0.\n",
      " 0.         0.1757239  0.43921417 0.        ]\n",
      "18\n",
      "[0.01302068 0.0110968  0.02055344 0.01018857 0.01579768 0.\n",
      " 0.04062563 0.         0.03458407 0.08806426 0.14197601 0.\n",
      " 0.         0.17575058 0.43923519 0.        ]\n",
      "19\n",
      "[0.01323396 0.01122105 0.02064717 0.01025608 0.01590393 0.\n",
      " 0.0406558  0.         0.03463806 0.08809116 0.14199554 0.\n",
      " 0.         0.17576923 0.43924999 0.        ]\n",
      "20\n",
      "[0.01339823 0.01131661 0.02071891 0.01030777 0.01598505 0.\n",
      " 0.04067861 0.         0.03467857 0.08811084 0.14200986 0.\n",
      " 0.         0.17578252 0.43926059 0.        ]\n",
      "21\n",
      "[0.01352453 0.01139001 0.02077383 0.01034734 0.01604704 0.\n",
      " 0.04069592 0.         0.03470911 0.08812537 0.14202047 0.\n",
      " 0.         0.17579212 0.4392683  0.        ]\n",
      "22\n",
      "[0.01362153 0.01144634 0.02081586 0.01037763 0.01609442 0.\n",
      " 0.04070908 0.         0.03473223 0.0881362  0.1420284  0.\n",
      " 0.         0.17579915 0.43927396 0.        ]\n",
      "23\n",
      "[0.01369595 0.01148954 0.02084803 0.01040082 0.01613065 0.\n",
      " 0.04071911 0.         0.03474977 0.08814433 0.14203435 0.\n",
      " 0.         0.17580436 0.43927817 0.        ]\n",
      "24\n",
      "[0.01375302 0.01152265 0.02087265 0.01041857 0.01615836 0.\n",
      " 0.04072675 0.         0.03476312 0.08815046 0.14203884 0.\n",
      " 0.         0.17580825 0.43928131 0.        ]\n",
      "25\n",
      "[0.01379676 0.01154802 0.0208915  0.01043216 0.01617956 0.\n",
      " 0.04073259 0.         0.03477328 0.08815509 0.14204225 0.\n",
      " 0.         0.17581116 0.43928368 0.        ]\n",
      "26\n",
      "[0.01383028 0.01156745 0.02090592 0.01044256 0.01619578 0.\n",
      " 0.04073704 0.         0.03478104 0.08815861 0.14204483 0.\n",
      " 0.         0.17581336 0.43928547 0.        ]\n",
      "27\n",
      "[0.01385594 0.01158233 0.02091696 0.01045052 0.01620819 0.\n",
      " 0.04074045 0.         0.03478696 0.08816129 0.1420468  0.\n",
      " 0.         0.17581503 0.43928683 0.        ]\n",
      "28\n",
      "[0.0138756  0.01159372 0.02092541 0.01045661 0.01621769 0.\n",
      " 0.04074305 0.         0.03479148 0.08816333 0.1420483  0.\n",
      " 0.         0.1758163  0.43928786 0.        ]\n",
      "29\n",
      "[0.01389065 0.01160245 0.02093188 0.01046128 0.01622496 0.\n",
      " 0.04074505 0.         0.03479494 0.08816489 0.14204945 0.\n",
      " 0.         0.17581726 0.43928864 0.        ]\n",
      "30\n",
      "[0.01390218 0.01160913 0.02093683 0.01046485 0.01623052 0.\n",
      " 0.04074657 0.         0.03479759 0.08816607 0.14205032 0.\n",
      " 0.         0.17581799 0.43928924 0.        ]\n",
      "31\n",
      "[0.013911   0.01161424 0.02094062 0.01046758 0.01623478 0.\n",
      " 0.04074774 0.         0.03479961 0.08816698 0.14205099 0.\n",
      " 0.         0.17581855 0.4392897  0.        ]\n",
      "32\n",
      "[0.01391775 0.01161815 0.02094352 0.01046967 0.01623804 0.\n",
      " 0.04074863 0.         0.03480116 0.08816767 0.1420515  0.\n",
      " 0.         0.17581898 0.43929004 0.        ]\n",
      "33\n",
      "[0.01392292 0.01162115 0.02094574 0.01047127 0.01624053 0.\n",
      " 0.04074931 0.         0.03480234 0.08816821 0.14205189 0.\n",
      " 0.         0.17581931 0.43929031 0.        ]\n",
      "34\n",
      "[0.01392688 0.01162344 0.02094744 0.0104725  0.01624244 0.\n",
      " 0.04074983 0.         0.03480325 0.08816861 0.14205219 0.\n",
      " 0.         0.17581956 0.43929051 0.        ]\n",
      "35\n",
      "[0.01392991 0.0116252  0.02094874 0.01047343 0.0162439  0.\n",
      " 0.04075023 0.         0.03480394 0.08816892 0.14205242 0.\n",
      " 0.         0.17581975 0.43929067 0.        ]\n",
      "36\n",
      "[0.01393223 0.01162654 0.02094974 0.01047415 0.01624502 0.\n",
      " 0.04075054 0.         0.03480447 0.08816916 0.14205259 0.\n",
      " 0.         0.17581989 0.43929079 0.        ]\n",
      "37\n",
      "[0.01393401 0.01162757 0.0209505  0.0104747  0.01624587 0.\n",
      " 0.04075077 0.         0.03480488 0.08816934 0.14205273 0.\n",
      " 0.         0.17582001 0.43929088 0.        ]\n",
      "38\n",
      "[0.01393536 0.01162836 0.02095108 0.01047512 0.01624653 0.\n",
      " 0.04075095 0.         0.03480519 0.08816948 0.14205283 0.\n",
      " 0.         0.17582009 0.43929095 0.        ]\n",
      "39\n",
      "[0.0139364  0.01162896 0.02095153 0.01047544 0.01624703 0.\n",
      " 0.04075109 0.         0.03480542 0.08816959 0.14205291 0.\n",
      " 0.         0.17582016 0.439291   0.        ]\n",
      "40\n",
      "[0.0139372  0.01162942 0.02095187 0.01047569 0.01624741 0.\n",
      " 0.04075119 0.         0.03480561 0.08816967 0.14205297 0.\n",
      " 0.         0.17582021 0.43929104 0.        ]\n",
      "41\n",
      "[0.01393781 0.01162978 0.02095213 0.01047588 0.01624771 0.\n",
      " 0.04075127 0.         0.03480574 0.08816973 0.14205301 0.\n",
      " 0.         0.17582025 0.43929108 0.        ]\n",
      "42\n",
      "[0.01393827 0.01163005 0.02095233 0.01047602 0.01624793 0.\n",
      " 0.04075134 0.         0.03480585 0.08816978 0.14205305 0.\n",
      " 0.         0.17582027 0.4392911  0.        ]\n",
      "43\n",
      "[0.01393863 0.01163025 0.02095249 0.01047613 0.0162481  0.\n",
      " 0.04075138 0.         0.03480593 0.08816981 0.14205307 0.\n",
      " 0.         0.1758203  0.43929112 0.        ]\n",
      "44\n",
      "[0.0139389  0.01163041 0.0209526  0.01047622 0.01624824 0.\n",
      " 0.04075142 0.         0.034806   0.08816984 0.14205309 0.\n",
      " 0.         0.17582031 0.43929113 0.        ]\n",
      "45\n",
      "[0.01393911 0.01163053 0.02095269 0.01047628 0.01624834 0.\n",
      " 0.04075145 0.         0.03480604 0.08816986 0.14205311 0.\n",
      " 0.         0.17582033 0.43929114 0.        ]\n",
      "46\n",
      "[0.01393927 0.01163062 0.02095276 0.01047633 0.01624841 0.\n",
      " 0.04075147 0.         0.03480608 0.08816988 0.14205312 0.\n",
      " 0.         0.17582034 0.43929115 0.        ]\n",
      "47\n",
      "[0.0139394  0.0116307  0.02095281 0.01047637 0.01624847 0.\n",
      " 0.04075148 0.         0.03480611 0.08816989 0.14205313 0.\n",
      " 0.         0.17582034 0.43929116 0.        ]\n",
      "48\n",
      "[0.01393949 0.01163075 0.02095285 0.0104764  0.01624852 0.\n",
      " 0.0407515  0.         0.03480613 0.0881699  0.14205314 0.\n",
      " 0.         0.17582035 0.43929116 0.        ]\n",
      "49\n",
      "[0.01393956 0.01163079 0.02095289 0.01047642 0.01624855 0.\n",
      " 0.04075151 0.         0.03480615 0.08816991 0.14205314 0.\n",
      " 0.         0.17582036 0.43929117 0.        ]\n",
      "50\n",
      "[0.01393962 0.01163082 0.02095291 0.01047644 0.01624858 0.\n",
      " 0.04075151 0.         0.03480616 0.08816991 0.14205315 0.\n",
      " 0.         0.17582036 0.43929117 0.        ]\n",
      "51\n",
      "[0.01393966 0.01163085 0.02095293 0.01047645 0.0162486  0.\n",
      " 0.04075152 0.         0.03480617 0.08816992 0.14205315 0.\n",
      " 0.         0.17582036 0.43929117 0.        ]\n",
      "52\n",
      "[0.01393969 0.01163087 0.02095294 0.01047646 0.01624861 0.\n",
      " 0.04075152 0.         0.03480618 0.08816992 0.14205315 0.\n",
      " 0.         0.17582036 0.43929117 0.        ]\n",
      "53\n",
      "[0.01393972 0.01163088 0.02095295 0.01047647 0.01624863 0.\n",
      " 0.04075153 0.         0.03480618 0.08816992 0.14205316 0.\n",
      " 0.         0.17582036 0.43929117 0.        ]\n",
      "54\n",
      "[0.01393973 0.01163089 0.02095296 0.01047647 0.01624864 0.\n",
      " 0.04075153 0.         0.03480619 0.08816993 0.14205316 0.\n",
      " 0.         0.17582037 0.43929117 0.        ]\n",
      "55\n",
      "[0.01393975 0.0116309  0.02095297 0.01047648 0.01624864 0.\n",
      " 0.04075153 0.         0.03480619 0.08816993 0.14205316 0.\n",
      " 0.         0.17582037 0.43929117 0.        ]\n",
      "56\n",
      "[0.01393976 0.01163091 0.02095297 0.01047648 0.01624865 0.\n",
      " 0.04075153 0.         0.03480619 0.08816993 0.14205316 0.\n",
      " 0.         0.17582037 0.43929118 0.        ]\n",
      "57\n",
      "[0.01393977 0.01163091 0.02095297 0.01047648 0.01624865 0.\n",
      " 0.04075153 0.         0.03480619 0.08816993 0.14205316 0.\n",
      " 0.         0.17582037 0.43929118 0.        ]\n",
      "array([0.01393977, 0.01163091, 0.02095297, 0.01047648, 0.01624865,\n",
      "       0.        , 0.04075153, 0.        , 0.03480619, 0.08816993,\n",
      "       0.14205316, 0.        , 0.        , 0.17582037, 0.43929118,\n",
      "       0.        ])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_expected_return(V, state_number, action, env, gamma):\n",
    "    expected_return = 0.0\n",
    "    possibilities = env.get_possibilities(state_number, action)\n",
    "    for state_info in possibilities: \n",
    "        r = state_info.reward\n",
    "        n = state_info.n\n",
    "        p = state_info.probability\n",
    "        expected_return += (p * (r + gamma * V[n]))\n",
    "    return expected_return \n",
    "\n",
    "\n",
    "def update_state_value(V, state_number, policy, env, gamma):\n",
    "    new_v = 0.0\n",
    "    for action, action_probability in policy[state_number].items():\n",
    "        expected_return = get_expected_return(V, state_number, action, env, gamma)\n",
    "        new_v += (action_probability * expected_return)\n",
    "    return new_v\n",
    "        \n",
    "    \n",
    "def policy_evaluation(env, policy, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.number_of_states)\n",
    "    i = 0\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        for state_number in range(env.number_of_states):\n",
    "            old_v = V[state_number]\n",
    "            new_v = update_state_value(V, state_number, policy, env, gamma)\n",
    "            value_difference = np.abs(old_v - new_v)\n",
    "            delta = max(delta, value_difference)\n",
    "            V[state_number] = new_v\n",
    "        i+=1\n",
    "        print(i)\n",
    "        print(V)\n",
    "        if delta < theta: break\n",
    "    return V\n",
    "\n",
    "policy = create_equiprobable_policy(env = lake_environment)\n",
    "V = policy_evaluation(lake_environment, policy)\n",
    "pprint(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[0.01393977, 0.01163091, 0.02095297, 0.01047648, 0.01624865, 0.        , 0.04075153, 0.        , 0.03480619, 0.08816993,\n",
    "       0.14205316, 0.        , 0.        , 0.17582037, 0.43929118,\n",
    "       0.        ] ==  [0.01393977, 0.01163091, 0.02095297, 0.01047648, 0.01624865, 0.,\n",
    " 0.04075153, 0.,         0.03480619, 0.08816993, 0.14205316, 0.,\n",
    " 0.,         0.17582037, 0.43929118, 0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
