# Things I want to check out soon 


## Query-Efficient Black-box Adversarial Examples (superceded)6 Apr 2018 
- CSAIL MIT Research
- This algorithm actually fools Neural Networks 1000x faster
- https://www.arxiv-vanity.com/papers/1712.07113/
- https://www.youtube.com/watch?v=sZViVi1rZPA
- https://www.csail.mit.edu/news/fooling-googles-image-recognition-ai-1000x-faster

## Fooling Neural Networks with 3D printed objects (Nov 2, 2017
- https://www.csail.mit.edu/news/fooling-neural-networks-w3d-printed-objects
- https://www.youtube.com/watch?time_continue=5&v=piYnd_wYlT8
- https://www.labsix.org/physical-objects-that-fool-neural-nets/
- https://arxiv.org/pdf/1707.07397.pdf
- Synthesizing Robust Adversarial Examples

## Visualizing and Understanding Deep Neural Networks by Matt Zeiler
- Feb 2, 2015, 47 minutes 
- Matthew Zeiler, PhD, Founder and CEO of Clarifai Inc, speaks about large convolutional neural networks.
These networks have recently demonstrated impressive object recognition performance making real world applications 
possible. However, there was no clear understanding of why they perform so well, or how they might be improved. 
In this talk, Matt covers a novel visualization technique that gives insight into the function of intermediate 
feature layers and the operation of the overall classifier. Used in a diagnostic role, these visualizations allow 
us to find model architectures that perform exceedingly well.
- https://www.youtube.com/watch?v=ghEmQSxT6tw

## "Towards Evaluating the Robustness of Neural Networks" 
by Nicholas Carlini and David Wagner, at IEEE Symposium on Security & Privacy, 2017.
- L0, L1, and L2 attacks 
- Implementations of the three attack algorithms in Tensorflow, which works strongly on Defense Distillation 
- https://github.com/carlini/nn_robust_attacks

## Adversarial Examples for Evaluating Reading Comprehension Systems
- Robin Jia, Percy Liang (Submitted on 23 Jul 2017)
- https://www.arxiv-vanity.com/papers/1707.07328/

## Understanding Neural Networks Through Deep Visualization
Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson
- Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps
- Submitted on 19 April 2014
- http://yosinski.com/deepvis#toolbox
- https://www.arxiv-vanity.com/papers/1312.6034/
- https://www.youtube.com/watch?v=AgkfIQ4IGaM
- https://github.com/yosinski/deep-visualization-toolbox
- http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf

## Recurrent Neural Networks Full-course Andrew Ng 
- https://www.youtube.com/playlist?list=PLBAGcD3siRDittPwQDGIIAWkjz-RucAc7

## Reinforcement Learning Explained - EDx by Mircosoft
- https://courses.edx.org/courses/course-v1:Microsoft+DAT257x+2T2018/course/

## Fast AI (PAPERSPACE)
- https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/paperspace.md
- https://github.com/fastai/fastai/tree/master/courses/dl2

## Arxiv Insights - Cool stuff
- https://www.youtube.com/channel/UCNIkB2IeJ-6AmZv7bQ1oBYg/videos
- OpenAI Five: Facing Human Pro's in Dota2
- Overcoming sparse rewards in Deep RL
- Introduction to reinforcement Learning
- Comparing humans with the best reinforcment Learning
